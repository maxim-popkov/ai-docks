{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import toml\n",
    "import shutil\n",
    "import zipfile\n",
    "from time import time\n",
    "\n",
    "# –≠—Ç–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π.\n",
    "# –ï—Å–ª–∏ –≤—ã –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ —Å–∫—Ä–∏–ø—Ç –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ, –≤—ã –º–æ–∂–µ—Ç–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏—Ö –∑–Ω–∞—á–µ–Ω–∏—è –∑–¥–µ—Å—å.\n",
    "model_url = \"YOUR_DEFAULT_MODEL_URL_HERE\"  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é URL-—Å—Å—ã–ª–∫—É –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –µ—Å—Ç—å.\n",
    "dependencies_installed = False\n",
    "model_file = None\n",
    "\n",
    "# –≠—Ç–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –¥—Ä—É–≥–∏–º–∏ —á–∞—Å—Ç—è–º–∏ –∫–æ–¥–∞.\n",
    "custom_dataset = None\n",
    "override_dataset_config_file = None\n",
    "override_config_file = None\n",
    "optimizer = \"AdamW8bit\"\n",
    "optimizer_args = None\n",
    "continue_from_lora = \"\"\n",
    "weighted_captions = False\n",
    "adjust_tags = False\n",
    "keep_tokens_weight = 1.0\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "project_name = input(\"–í–≤–µ–¥–∏—Ç–µ –∏–º—è –≤–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ (–Ω–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–æ–±–µ–ª–æ–≤): \")\n",
    "\n",
    "print(\"\"\"\n",
    "1. –û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (MyDrive/lora_training/datasets/project_name)\n",
    "2. –û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –ø–æ –ø—Ä–æ–µ–∫—Ç—É (/home/popkov-mi/Loras/project_name/dataset)\n",
    "\"\"\")\n",
    "folder_structure_choice = int(input(\"–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ (1/2): \"))\n",
    "\n",
    "if folder_structure_choice == 1:\n",
    "    folder_structure = \"Organize by category (MyDrive/lora_training/datasets/project_name)\"\n",
    "else:\n",
    "    folder_structure = \"Organize by project (/home/popkov-mi/Loras/project_name/dataset)\"\n",
    "\n",
    "print(\"\"\"\n",
    "1. Anime (animefull-final-pruned-fp16.safetensors)\n",
    "2. AnyLora (AnyLoRA_noVae_fp16-pruned.ckpt)\n",
    "3. Stable Diffusion (sd-v1-5-pruned-noema-fp16.safetensors)\n",
    "4. –£–∫–∞–∑–∞—Ç—å —Å–≤–æ—é\n",
    "\"\"\")\n",
    "training_model_choice = int(input(\"–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (1/2/3/4): \"))\n",
    "\n",
    "if training_model_choice == 4:\n",
    "    model_url = input(\"–í–≤–µ–¥–∏—Ç–µ URL-—Å—Å—ã–ª–∫—É –Ω–∞ –≤–∞—à—É –º–æ–¥–µ–ª—å: \")\n",
    "elif training_model_choice == 2:\n",
    "    model_url = \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16-pruned.ckpt\"\n",
    "elif training_model_choice == 1:\n",
    "    model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/animefull-final-pruned-fp16.safetensors\"\n",
    "else:\n",
    "    model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/sd-v1-5-pruned-noema-fp16.safetensors\"\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "resolution = int(input(\"–í–≤–µ–¥–∏—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ (512, 640, 768, 896, 1024): \"))\n",
    "flip_aug = input(\"–û–±—É—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º –∏ –ø–µ—Ä–µ–≤–µ—Ä–Ω—É—Ç–æ–º –≤–∏–¥–µ? (y/n): \").lower() == 'y'\n",
    "caption_extension = input(\"–í–≤–µ–¥–∏—Ç–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è –ø–æ–¥–ø–∏—Å–µ–π (–ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø–æ–¥–ø–∏—Å–µ–π): \")\n",
    "shuffle_tags = input(\"–ü–µ—Ä–µ–º–µ—à–∞—Ç—å —Ç–µ–≥–∏ –∞–Ω–∏–º–µ? (y/n): \").lower() == 'y'\n",
    "activation_tags = input(\"–í–≤–µ–¥–∏—Ç–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ–≥–∏ (0/1/2/3): \")\n",
    "keep_tokens = int(activation_tags)\n",
    "\n",
    "# –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–≤–æ–µ–≥–æ –∫–æ–¥–∞ –∑–¥–µ—Å—å...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —ç—Ç–∞–ø–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏\n",
    "num_repeats = 10\n",
    "preferred_unit = \"Epochs\"\n",
    "how_many = 10\n",
    "\n",
    "max_train_epochs = how_many if preferred_unit == \"Epochs\" else None\n",
    "max_train_steps = how_many if preferred_unit == \"Steps\" else None\n",
    "save_every_n_epochs = 1\n",
    "keep_only_last_n_epochs = 10\n",
    "train_batch_size = 2\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "unet_lr = 5e-4\n",
    "text_encoder_lr = 1e-4\n",
    "lr_scheduler = \"cosine_with_restarts\"\n",
    "lr_scheduler_number = 3\n",
    "lr_scheduler_num_cycles = lr_scheduler_number if lr_scheduler == \"cosine_with_restarts\" else 0\n",
    "lr_scheduler_power = lr_scheduler_number if lr_scheduler == \"polynomial\" else 0\n",
    "lr_warmup_ratio = 0.05\n",
    "lr_warmup_steps = 0\n",
    "min_snr_gamma = True\n",
    "min_snr_gamma_value = 5.0 if min_snr_gamma else None\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç—Ä—É–∫—Ç—É—Ä—ã LoRA\n",
    "lora_type = \"LoRA\"\n",
    "network_dim = 16\n",
    "network_alpha = 8\n",
    "conv_dim = 8\n",
    "conv_alpha = 4\n",
    "\n",
    "network_module = \"networks.lora\"\n",
    "network_args = None\n",
    "if lora_type.lower() == \"locon\":\n",
    "    network_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n",
    "\n",
    "# TODO: –ó–¥–µ—Å—å –¥–æ–±–∞–≤—å—Ç–µ –∫–æ–¥ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏, –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö, –∑–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –∏ —Ç.–¥.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "optimizer_args = None\n",
    "if optimizer.lower() == \"prodigy\" or \"dadapt\" in optimizer.lower():\n",
    "    if override_values_for_dadapt_and_prodigy:\n",
    "        unet_lr = 0.5\n",
    "        text_encoder_lr = 0.5\n",
    "        lr_scheduler = \"constant_with_warmup\"\n",
    "        lr_warmup_ratio = 0.05\n",
    "        network_alpha = network_dim\n",
    "\n",
    "    if not optimizer_args:\n",
    "        optimizer_args = [\"decouple=True\",\"weight_decay=0.01\",\"betas=[0.9,0.999]\"]\n",
    "        if optimizer == \"Prodigy\":\n",
    "            optimizer_args.extend([\"d_coef=2\",\"use_bias_correction=True\"])\n",
    "            if lr_warmup_ratio > 0:\n",
    "                optimizer_args.append(\"safeguard_warmup=True\")\n",
    "            else:\n",
    "                optimizer_args.append(\"safeguard_warmup=False\")\n",
    "\n",
    "root_dir = \"/home/popkov-mi/Loras\"\n",
    "deps_dir = os.path.join(root_dir, \"deps\")\n",
    "repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
    "\n",
    "# –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –ø–æ–¥ –≤–∞—à —Å–µ—Ä–≤–µ—Ä\n",
    "main_dir = root_dir\n",
    "log_folder = os.path.join(main_dir, \"_logs\")\n",
    "config_folder = os.path.join(main_dir, project_name)\n",
    "images_folder = os.path.join(main_dir, project_name, \"dataset\")\n",
    "output_folder = os.path.join(main_dir, project_name, \"output\")\n",
    "\n",
    "config_file = os.path.join(config_folder, \"training_config.toml\")\n",
    "dataset_config_file = os.path.join(config_folder, \"dataset_config.toml\")\n",
    "accelerate_config_file = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\"–í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–º–∞–Ω–¥—É –≤ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ.\"\"\"\n",
    "    process = subprocess.Popen(command, shell=True)\n",
    "    process.communicate()\n",
    "\n",
    "def clone_repo():\n",
    "    os.chdir(root_dir)\n",
    "    run_command(f\"git clone https://github.com/kohya-ss/sd-scripts {repo_dir}\")\n",
    "    os.chdir(repo_dir)\n",
    "    if COMMIT:\n",
    "        run_command(f\"git reset --hard {COMMIT}\")\n",
    "    run_command(\"wget https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/xformers-fix/requirements.txt -q -O requirements.txt\")\n",
    "\n",
    "def install_dependencies():\n",
    "    clone_repo()\n",
    "    run_command(\"apt -y update\")\n",
    "    run_command(\"apt -y install aria2\")\n",
    "    run_command(\"pip install --upgrade -r requirements.txt\")\n",
    "    if XFORMERS:\n",
    "        run_command(\"pip install xformers==0.0.22.post4\")\n",
    "\n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ kohya\n",
    "    if LOAD_TRUNCATED_IMAGES:\n",
    "        run_command('sed -i \\'s/from PIL import Image/from PIL import Image, ImageFile\\\\nImageFile.LOAD_TRUNCATED_IMAGES=True/g\\' library/train_util.py')\n",
    "    if BETTER_EPOCH_NAMES:\n",
    "        run_command('sed -i \\'s/{:06d}/{:02d}/g\\' library/train_util.py')\n",
    "        run_command('sed -i \\'s/\".\" + args.save_model_as)/\"-{:02d}.\".format(num_train_epochs) + args.save_model_as)/g\\' train_network.py')\n",
    "\n",
    "    from accelerate.utils import write_basic_config\n",
    "    if not os.path.exists(accelerate_config_file):\n",
    "        write_basic_config(save_location=accelerate_config_file)\n",
    "\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "    os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
    "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset():\n",
    "    global lr_warmup_steps, lr_warmup_ratio, caption_extension, keep_tokens, keep_tokens_weight, weighted_captions, adjust_tags\n",
    "    supported_types = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
    "\n",
    "    print(\"\\nüíø Checking dataset...\")\n",
    "    if not project_name.strip() or any(c in project_name for c in \" .()\\\"'\\\\/\"):\n",
    "        print(\"üí• Error: Please choose a valid project name.\")\n",
    "        return\n",
    "\n",
    "    if custom_dataset:\n",
    "        try:\n",
    "            datconf = toml.loads(custom_dataset)\n",
    "            datasets = [d for d in datconf[\"datasets\"][0][\"subsets\"]]\n",
    "        except:\n",
    "            print(f\"üí• Error: Your custom dataset is invalid or contains an error! Please check the original template.\")\n",
    "            return\n",
    "        reg = [d.get(\"image_dir\") for d in datasets if d.get(\"is_reg\", False)]\n",
    "        datasets_dict = {d[\"image_dir\"]: d[\"num_repeats\"] for d in datasets}\n",
    "        folders = datasets_dict.keys()\n",
    "        files = [f for folder in folders for f in os.listdir(folder)]\n",
    "        images_repeats = {folder: (len([f for f in os.listdir(folder) if f.lower().endswith(supported_types)]), datasets_dict[folder]) for folder in folders}\n",
    "    else:\n",
    "        reg = []\n",
    "        folders = [images_folder]\n",
    "        files = os.listdir(images_folder)\n",
    "        images_repeats = {images_folder: (len([f for f in files if f.lower().endswith(supported_types)]), num_repeats)}\n",
    "\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            print(f\"üí• Error: The folder {folder} doesn't exist.\")\n",
    "            return\n",
    "    for folder, (img, rep) in images_repeats.items():\n",
    "        if not img:\n",
    "            print(f\"üí• Error: Your {folder} folder is empty.\")\n",
    "            return\n",
    "    for f in files:\n",
    "        if not f.lower().endswith(\".txt\") and not f.lower().endswith(supported_types):\n",
    "            print(f\"üí• Error: Invalid file in dataset: \\\"{f}\\\". Aborting.\")\n",
    "            return\n",
    "\n",
    "    if not [txt for txt in files if txt.lower().endswith(\".txt\")]:\n",
    "        caption_extension = \"\"\n",
    "    if continue_from_lora and not (continue_from_lora.endswith(\".safetensors\") and os.path.exists(continue_from_lora)):\n",
    "        print(f\"üí• Error: Invalid path to existing Lora. Example: /content/drive/MyDrive/Loras/example.safetensors\")\n",
    "        return\n",
    "\n",
    "    pre_steps_per_epoch = sum(img*rep for (img, rep) in images_repeats.values())\n",
    "    steps_per_epoch = pre_steps_per_epoch/train_batch_size\n",
    "    total_steps = max_train_steps or int(max_train_epochs*steps_per_epoch)\n",
    "    estimated_epochs = int(total_steps/steps_per_epoch)\n",
    "    lr_warmup_steps = int(total_steps*lr_warmup_ratio)\n",
    "\n",
    "    for folder, (img, rep) in images_repeats.items():\n",
    "        print(\"üìÅ\"+folder.replace(\"/content/drive/\", \"\") + (\" (Regularization)\" if folder in reg else \"\"))\n",
    "        print(f\"üìà Found {img} images with {rep} repeats, equaling {img*rep} steps.\")\n",
    "\n",
    "    print(f\"üìâ Divide {pre_steps_per_epoch} steps by {train_batch_size} batch size to get {steps_per_epoch} steps per epoch.\")\n",
    "    if max_train_epochs:\n",
    "        print(f\"üîÆ There will be {max_train_epochs} epochs, for around {total_steps} total training steps.\")\n",
    "    else:\n",
    "        print(f\"üîÆ There will be {total_steps} steps, divided into {estimated_epochs} epochs and then some.\")\n",
    "\n",
    "    if total_steps > 10000:\n",
    "        print(\"üí• Error: Your total steps are too high. You probably made a mistake. Aborting...\")\n",
    "        return\n",
    "\n",
    "    if adjust_tags:\n",
    "        print(f\"\\nüìé Weighted tags: {'ON' if weighted_captions else 'OFF'}\")\n",
    "        if weighted_captions:\n",
    "            print(f\"üìé Will use {keep_tokens_weight} weight on {keep_tokens} activation tag(s)\")\n",
    "        print(\"üìé Adjusting tags...\")\n",
    "        adjust_weighted_tags(folders, keep_tokens, keep_tokens_weight, weighted_captions)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def adjust_weighted_tags(folders, keep_tokens: int, keep_tokens_weight: float, weighted_captions: bool):\n",
    "    weighted_tag = re.compile(r\"\\((.+?):[.\\d]+\\)(,|$)\")\n",
    "    for folder in folders:\n",
    "        for txt in [f for f in os.listdir(folder) if f.lower().endswith(\".txt\")]:\n",
    "            with open(os.path.join(folder, txt), 'r') as f:\n",
    "                content = f.read()\n",
    "                # reset previous changes\n",
    "                content = content.replace('\\\\', '')\n",
    "                content = weighted_tag.sub(r'\\1\\2', content)\n",
    "                if weighted_captions:\n",
    "                # re-apply changes\n",
    "                    content = content.replace(r'(', r'\\(').replace(r')', r'\\)').replace(r':', r'\\:')\n",
    "            if keep_tokens_weight > 1:\n",
    "                tags = [s.strip() for s in content.split(\",\")]\n",
    "                for i in range(min(keep_tokens, len(tags))):\n",
    "                    tags[i] = f'({tags[i]}:{keep_tokens_weight})'\n",
    "                    content = \", \".join(tags)\n",
    "            with open(os.path.join(folder, txt), 'w') as f:\n",
    "                f.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "\n",
    "def create_config():\n",
    "    global dataset_config_file, config_file, model_file\n",
    "\n",
    "    if override_config_file:\n",
    "        config_file = override_config_file\n",
    "        print(f\"\\n‚≠ï Using custom config file {config_file}\")\n",
    "    else:\n",
    "        config_dict = {\n",
    "            \"additional_network_arguments\": {\n",
    "                \"unet_lr\": unet_lr,\n",
    "                \"text_encoder_lr\": text_encoder_lr,\n",
    "                \"network_dim\": network_dim,\n",
    "                \"network_alpha\": network_alpha,\n",
    "                \"network_module\": network_module,\n",
    "                \"network_args\": network_args,\n",
    "                \"network_train_unet_only\": True if text_encoder_lr == 0 else None,\n",
    "                \"network_weights\": continue_from_lora if continue_from_lora else None\n",
    "            },\n",
    "            \"optimizer_arguments\": {\n",
    "                \"learning_rate\": unet_lr,\n",
    "                \"lr_scheduler\": lr_scheduler,\n",
    "                \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n",
    "                \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n",
    "                \"lr_warmup_steps\": lr_warmup_steps if lr_scheduler != \"constant\" else None,\n",
    "                \"optimizer_type\": optimizer,\n",
    "                \"optimizer_args\": optimizer_args if optimizer_args else None,\n",
    "            },\n",
    "            \"training_arguments\": {\n",
    "                \"max_train_steps\": max_train_steps,\n",
    "                \"max_train_epochs\": max_train_epochs,\n",
    "                \"save_every_n_epochs\": save_every_n_epochs,\n",
    "                \"save_last_n_epochs\": keep_only_last_n_epochs,\n",
    "                \"train_batch_size\": train_batch_size,\n",
    "                \"clip_skip\": 2,\n",
    "                \"min_snr_gamma\": min_snr_gamma_value,\n",
    "                \"weighted_captions\": weighted_captions,\n",
    "                \"seed\": 42,\n",
    "                \"max_token_length\": 225,\n",
    "                \"xformers\": XFORMERS,\n",
    "                \"max_data_loader_n_workers\": 8,\n",
    "                \"persistent_data_loader_workers\": True,\n",
    "                \"save_precision\": \"fp16\",\n",
    "                \"mixed_precision\": \"fp16\",\n",
    "                \"output_dir\": output_folder,\n",
    "                \"logging_dir\": log_folder,\n",
    "                \"output_name\": project_name,\n",
    "                \"log_prefix\": project_name,\n",
    "            },\n",
    "            \"model_arguments\": {\n",
    "                \"pretrained_model_name_or_path\": model_file,\n",
    "                \"v2\": custom_model_is_based_on_sd2,\n",
    "                \"v_parameterization\": True if custom_model_is_based_on_sd2 else None,\n",
    "            },\n",
    "            \"saving_arguments\": {\n",
    "                \"save_model_as\": \"safetensors\",\n",
    "            },\n",
    "            \"dreambooth_arguments\": {\n",
    "                \"prior_loss_weight\": 1.0,\n",
    "            },\n",
    "            \"dataset_arguments\": {\n",
    "                \"cache_latents\": True,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        for key in config_dict:\n",
    "            if isinstance(config_dict[key], dict):\n",
    "                config_dict[key] = {k: v for k, v in config_dict[key].items() if v is not None}\n",
    "\n",
    "        with open(config_file, \"w\") as f:\n",
    "            f.write(toml.dumps(config_dict))\n",
    "        print(f\"\\nüìÑ Config saved to {config_file}\")\n",
    "\n",
    "    if override_dataset_config_file:\n",
    "        dataset_config_file = override_dataset_config_file\n",
    "        print(f\"‚≠ï Using custom dataset config file {dataset_config_file}\")\n",
    "    else:\n",
    "        dataset_config_dict = {\n",
    "            \"general\": {\n",
    "                \"resolution\": resolution,\n",
    "                \"shuffle_caption\": shuffle_caption,\n",
    "                \"keep_tokens\": keep_tokens,\n",
    "                \"flip_aug\": flip_aug,\n",
    "                \"caption_extension\": caption_extension,\n",
    "                \"enable_bucket\": True,\n",
    "                \"bucket_reso_steps\": 64,\n",
    "                \"bucket_no_upscale\": False,\n",
    "                \"min_bucket_reso\": 320 if resolution > 640 else 256,\n",
    "                \"max_bucket_reso\": 1280 if resolution > 640 else 1024,\n",
    "            },\n",
    "            \"datasets\": toml.loads(custom_dataset)[\"datasets\"] if custom_dataset else [\n",
    "                {\n",
    "                    \"subsets\": [\n",
    "                        {\n",
    "                            \"num_repeats\": num_repeats,\n",
    "                            \"image_dir\": images_folder,\n",
    "                            \"class_tokens\": None if caption_extension else project_name\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        for key in dataset_config_dict:\n",
    "            if isinstance(dataset_config_dict[key], dict):\n",
    "                dataset_config_dict[key] = {k: v for k, v in dataset_config_dict[key].items() if v is not None}\n",
    "\n",
    "        with open(dataset_config_file, \"w\") as f:\n",
    "            f.write(toml.dumps(dataset_config_dict))\n",
    "        print(f\"üìÑ Dataset config saved to {dataset_config_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "def download_model():\n",
    "    global old_model_url, model_url, model_file\n",
    "    real_model_url = model_url.strip()\n",
    "\n",
    "    if real_model_url.lower().endswith((\".ckpt\", \".safetensors\")):\n",
    "        model_file = f\"/home/popkov-mi/Loras{real_model_url[real_model_url.rfind('/'):]}\"\n",
    "    else:\n",
    "        model_file = \"/home/popkov-mi/Loras/downloaded_model.safetensors\"\n",
    "        if os.path.exists(model_file):\n",
    "            subprocess.run([\"rm\", model_file])\n",
    "\n",
    "    if m := re.search(r\"(?:https?://)?(?:www\\.)?huggingface\\.co/[^/]+/[^/]+/blob\", model_url):\n",
    "        real_model_url = real_model_url.replace(\"blob\", \"resolve\")\n",
    "    elif m := re.search(r\"(?:https?://)?(?:www\\.)?civitai\\.com/models/([0-9]+)\", model_url):\n",
    "        real_model_url = f\"https://civitai.com/api/download/models/{m.group(1)}\"\n",
    "\n",
    "    # !aria2c \"{real_model_url}\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d / -o \"{model_file}\"\n",
    "\n",
    "    if model_file.lower().endswith(\".safetensors\"):\n",
    "        from safetensors.torch import load_file as load_safetensors\n",
    "        try:\n",
    "            test = load_safetensors(model_file)\n",
    "            del test\n",
    "        except Exception as e:\n",
    "        #if \"HeaderTooLarge\" in str(e):\n",
    "        new_model_file = os.path.splitext(model_file)[0]+\".ckpt\"\n",
    "        # !mv \"{model_file}\" \"{new_model_file}\"\n",
    "        model_file = new_model_file\n",
    "        print(f\"Renamed model to {os.path.splitext(model_file)[0]}.ckpt\")\n",
    "\n",
    "    if model_file.lower().endswith(\".ckpt\"):\n",
    "        from torch import load as load_ckpt\n",
    "        try:\n",
    "        test = load_ckpt(model_file)\n",
    "        del test\n",
    "        except Exception as e:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global dependencies_installed\n",
    "\n",
    "    for dir in (main_dir, deps_dir, repo_dir, log_folder, images_folder, output_folder, config_folder):\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    if not validate_dataset():\n",
    "        return\n",
    "\n",
    "    if not dependencies_installed:\n",
    "        print(\"\\nüè≠ Installing dependencies...\\n\")\n",
    "        t0 = time()\n",
    "        install_dependencies()\n",
    "        t1 = time()\n",
    "        dependencies_installed = True\n",
    "        print(f\"\\n‚úÖ Installation finished in {int(t1-t0)} seconds.\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Dependencies already installed.\")\n",
    "\n",
    "    if old_model_url != model_url or not model_file or not os.path.exists(model_file):\n",
    "        print(\"\\nüîÑ Downloading model...\")\n",
    "        if not download_model():\n",
    "            print(\"\\nüí• Error: The model you selected is invalid or corrupted, or couldn't be downloaded. You can use a civitai or huggingface link, or any direct download link.\")\n",
    "        return\n",
    "        print()\n",
    "    else:\n",
    "        print(\"\\nüîÑ Model already downloaded.\\n\")\n",
    "\n",
    "    create_config()\n",
    "\n",
    "    print(\"\\n‚≠ê Starting trainer...\\n\")\n",
    "    os.chdir(repo_dir)\n",
    "    subprocess.run([\"accelerate\", \"launch\", \"--config_file={}\".format(accelerate_config_file), \"--num_cpu_threads_per_process=1\", \"train_network.py\", \"--dataset_config={}\".format(dataset_config_file), \"--config_file={}\".format(config_file)])\n",
    "\n",
    "    # –ó–∞–º–µ–Ω–∏–º –≤—ã–≤–æ–¥ –≤ IPython –Ω–∞ –æ–±—ã—á–Ω—ã–π print\n",
    "    print(\"‚úÖ Done! Check your Lora files in /home/popkov-mi/Loras\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
